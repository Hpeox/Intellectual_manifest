{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "import cv2, time\n",
    "# from PIL import Image\n",
    "# from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchmetrics\n",
    "import torchvision.models as models\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "train_path = glob.glob(\"./data/sample/*/*\")\n",
    "test_path = glob.glob(\"./data/test/*\")\n",
    "\n",
    "train_path.sort()\n",
    "test_path.sort()\n",
    "\n",
    "# train_df = pd.read_csv(\"data/train.csv\")\n",
    "# train_df = train_df.sort_values(by=\"name\")\n",
    "# train_label = train_df[\"label\"].values\n",
    "\n",
    "train_label = [np.int64(0) for i in range(480)]+[np.int64(1) for i in range(2400)]\n",
    "\n",
    "# 自定义数据集\n",
    "# 带有图片缓存的逻辑\n",
    "DATA_CACHE = {}\n",
    "\n",
    "\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.img_path[index] in DATA_CACHE:\n",
    "            img = DATA_CACHE[self.img_path[index]]\n",
    "        else:\n",
    "            img = cv2.imread(self.img_path[index])\n",
    "            DATA_CACHE[self.img_path[index]] = img\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        img = img.transpose([2, 0, 1])\n",
    "        return img, torch.from_numpy(np.array(self.img_label[index]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "dataset = XunFeiDataset(\n",
    "    train_path,\n",
    "    train_label,\n",
    "    A.Compose(\n",
    "        [\n",
    "            A.RandomRotate90(),\n",
    "            A.Resize(256, 256),\n",
    "            A.RandomCrop(224, 224),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset=dataset, lengths=[0.95, 0.05], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# 训练集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "# 验证集\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "# 测试集\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(\n",
    "        test_path,\n",
    "        [0] * len(test_path),\n",
    "        A.Compose(\n",
    "            [\n",
    "                A.Resize(256, 256),\n",
    "                A.RandomCrop(224, 224),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.RandomBrightnessContrast(p=0.5),\n",
    "                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=50,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=cv2.imread(train_path[0])\n",
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XunFeiNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet18, self).__init__()\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(512, 2)\n",
    "        self.resnet = model\n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "    \n",
    "class XunFeiNet34(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet34, self).__init__()\n",
    "        model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(512, 2)\n",
    "        self.resnet = model\n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "    \n",
    "class XunFeiNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet50, self).__init__()\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(2048, 2)\n",
    "        self.resnet = model\n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "\n",
    "class XunFeiNet101(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet101, self).__init__()\n",
    "        model = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(2048, 2)\n",
    "        self.resnet = model\n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "\n",
    "class XunFeiNet121(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet121, self).__init__()\n",
    "        model = models.densenet121(num_classes=2)\n",
    "        # model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        # model.fc = nn.Linear(512, 2)\n",
    "        self.resnet = model\n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "    \n",
    "class XunFeiNet152(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet152, self).__init__()\n",
    "        model = models.resnet152(weights=models.ResNet152_Weights.DEFAULT)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(2048, 2)\n",
    "        self.resnet = model\n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "\n",
    "\n",
    "model18 = XunFeiNet18().to(device)\n",
    "model34 = XunFeiNet34().to(device)\n",
    "model50 = XunFeiNet50().to(device)\n",
    "model101 = XunFeiNet101().to(device)\n",
    "model121 = XunFeiNet121().to(device)\n",
    "model152 = XunFeiNet152().to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train(train_loader, model, criterion, optimizer):\n",
    "    start = time.time()\n",
    "    start_batch = [start, 0]\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds = torch.tensor([])\n",
    "    target_all = torch.tensor([])\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i + 1) % 10 == 0:\n",
    "        #     start_batch[(1+(i + 1) // 100) % 2] = time.time()\n",
    "        #     print(\n",
    "        #         \"Train loss\",\n",
    "        #         loss.item(),\n",
    "        #         \"t={}s\".format(\n",
    "        #             start_batch[(1+(i + 1) // 100) % 2]\n",
    "        #             - start_batch[((i + 1) // 100) % 2]\n",
    "        #         ),\n",
    "        #     )\n",
    "\n",
    "        preds = torch.cat((preds, output.cpu().argmax(1)))\n",
    "        target_all = torch.cat((target_all, target.cpu()))\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    val_acc = torchmetrics.functional.classification.multiclass_f1_score(\n",
    "        preds, target_all, num_classes=2, average=\"macro\"\n",
    "    )\n",
    "    print(\"t={}s\".format(time.time() - start))\n",
    "    print(\"F1 score\", val_acc)\n",
    "    return train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "# 模型验证\n",
    "def validate(val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    preds = torch.tensor([])\n",
    "    target_all = torch.tensor([])\n",
    "    val_loss=0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            # val_acc += (output.argmax(1) == target).sum().item()\n",
    "            preds = torch.cat((preds, output.cpu().argmax(1)))\n",
    "            target_all = torch.cat((target_all, target.cpu()))\n",
    "\n",
    "        val_acc = torchmetrics.functional.classification.multiclass_f1_score(\n",
    "            preds, target_all, num_classes=2, average=\"macro\"\n",
    "        )\n",
    "        val_loss += loss.item()\n",
    "    # return val_acc / len(val_loader.dataset)\n",
    "    return val_acc,val_loss/len(val_loader)\n",
    "\n",
    "\n",
    "# 模型预测\n",
    "def predict(test_loader, model):\n",
    "    model.eval()\n",
    "\n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            input = input.to(device)\n",
    "            output = model(input)\n",
    "            test_pred.append(output.data.cpu().numpy())\n",
    "\n",
    "    return np.vstack(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for best model\n",
    "model=model152\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.000005)\n",
    "# model=model101\n",
    "epochs = 0\n",
    "last_acc = 0\n",
    "val_acc = 0.001\n",
    "while last_acc < val_acc:\n",
    "    last_acc = val_acc\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc,val_loss = validate(val_loader, model, criterion)\n",
    "    # train_acc = validate(train_loader, model)\n",
    "    print(\n",
    "        \"epoch {} :\".format(epochs + 1), \"train_loss:\", train_loss, 'val_loss:', val_loss,\"val_f1:\", val_acc\n",
    "    )\n",
    "    epochs += 1\n",
    "    if val_acc>last_acc:\n",
    "        torch.save(model.state_dict(),\"./model/baseline_152.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for best model\n",
    "model=model101\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.000005)\n",
    "# model=model101\n",
    "epochs = 0\n",
    "last_acc = 0\n",
    "val_acc = 0.001\n",
    "while last_acc < val_acc:\n",
    "    last_acc = val_acc\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc,val_loss = validate(val_loader, model, criterion)\n",
    "    # train_acc = validate(train_loader, model)\n",
    "    print(\n",
    "        \"epoch {} :\".format(epochs + 1), \"train_loss:\", train_loss, 'val_loss:', val_loss,\"val_f1:\", val_acc\n",
    "    )\n",
    "    epochs += 1\n",
    "    if val_acc>last_acc:\n",
    "        torch.save(model.state_dict(),\"./model/baseline_101.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for best model\n",
    "model=model50\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.000005)\n",
    "# model=model101\n",
    "epochs = 0\n",
    "last_acc = 0\n",
    "val_acc = 0.001\n",
    "while last_acc < val_acc:\n",
    "    last_acc = val_acc\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc,val_loss = validate(val_loader, model, criterion)\n",
    "    # train_acc = validate(train_loader, model)\n",
    "    print(\n",
    "        \"epoch {} :\".format(epochs + 1), \"train_loss:\", train_loss, 'val_loss:', val_loss,\"val_f1:\", val_acc\n",
    "    )\n",
    "    epochs += 1\n",
    "    if val_acc>last_acc:\n",
    "        torch.save(model.state_dict(),\"./model/baseline_50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for best model\n",
    "model=model34\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.000005)\n",
    "# model=model101\n",
    "epochs = 0\n",
    "last_acc = 0\n",
    "val_acc = 0.001\n",
    "while last_acc < val_acc:\n",
    "    last_acc = val_acc\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc,val_loss = validate(val_loader, model, criterion)\n",
    "    # train_acc = validate(train_loader, model)\n",
    "    print(\n",
    "        \"epoch {} :\".format(epochs + 1), \"train_loss:\", train_loss, 'val_loss:', val_loss,\"val_f1:\", val_acc\n",
    "    )\n",
    "    epochs += 1\n",
    "    if val_acc>last_acc:\n",
    "        torch.save(model.state_dict(),\"./model/baseline_34.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model50\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.000005)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc,val_loss = validate(val_loader, model, criterion)\n",
    "    print(\n",
    "        \"epoch {} :\".format(epoch + 1), \"train_loss:\", train_loss, 'val_loss:', val_loss,\"val_f1:\", val_acc\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对测试集多次预测\n",
    "pred = None\n",
    "model=model101\n",
    "model.load_state_dict(torch.load(\"./model/baseline_101.pth\"))\n",
    "for _ in range(3):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model)\n",
    "    else:\n",
    "        pred += predict(test_loader, model)\n",
    "    print(_+1)\n",
    "model=model152\n",
    "model.load_state_dict(torch.load(\"./model/baseline_152.pth\"))\n",
    "for _ in range(3):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model)\n",
    "    else:\n",
    "        pred += 0.9*predict(test_loader, model)\n",
    "    print(_+1)\n",
    "model=model50\n",
    "model.load_state_dict(torch.load(\"./model/baseline_50.pth\"))\n",
    "for _ in range(3):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model)\n",
    "    else:\n",
    "        pred += predict(test_loader, model)\n",
    "    print(_+1)\n",
    "model=model34\n",
    "model.load_state_dict(torch.load(\"./model/baseline_34.pth\"))\n",
    "for _ in range(3):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model)\n",
    "    else:\n",
    "        pred += 0.9*predict(test_loader, model)\n",
    "    print(_+1)\n",
    "submit = pd.DataFrame(\n",
    "    {\n",
    "        'name': [x.split('/')[-1] for x in test_path],\n",
    "        'label': pred.argmax(1)\n",
    "})\n",
    "\n",
    "# 生成提交结果\n",
    "submit = submit.sort_values(by='name')\n",
    "submit.to_csv('submit6.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "train_loss = 0.0\n",
    "model = model.to(device)\n",
    "for i, (input, target) in enumerate(train_loader):\n",
    "    input = input.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(input)\n",
    "    loss = criterion(output, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=4\n",
    "model=model101\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.0001)\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc,val_loss = validate(val_loader, model, criterion)\n",
    "    print(\n",
    "        \"epoch {} :\".format(epoch + 1), \"train_loss:\", train_loss, 'val_loss:', val_loss,\"val_f1:\", val_acc\n",
    "    )\n",
    "    epochs += 1\n",
    "torch.save(model.state_dict(),\"./model/baseline_test.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=3\n",
    "model101= XunFeiNet().to(device)\n",
    "model=model101\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.0001)\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc,val_loss = validate(val_loader, model, criterion)\n",
    "    print(\n",
    "        \"epoch {} :\".format(epoch + 1), \"train_loss:\", train_loss, 'val_loss:', val_loss,\"val_f1:\", val_acc\n",
    "    )\n",
    "    epochs += 1\n",
    "torch.save(model.state_dict(),\"./model/baseline_101.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = None\n",
    "model=model101\n",
    "model.load_state_dict(torch.load(\"./model/baseline_test.pth\"))\n",
    "for _ in range(3):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model)\n",
    "    else:\n",
    "        pred += predict(test_loader, model)\n",
    "    print(_+1)\n",
    "model.load_state_dict(torch.load(\"./model/baseline_101.pth\"))\n",
    "for _ in range(3):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model)\n",
    "    else:\n",
    "        pred += predict(test_loader, model)\n",
    "    print(_+1)\n",
    "model=model50\n",
    "model.load_state_dict(torch.load(\"./model/baseline_50.pth\"))\n",
    "for _ in range(3):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model)\n",
    "    else:\n",
    "        pred += predict(test_loader, model)\n",
    "    print(_+1)\n",
    "submit = pd.DataFrame(\n",
    "    {\n",
    "        'name': [x.split('/')[-1] for x in test_path],\n",
    "        'label': pred.argmax(1)\n",
    "})\n",
    "\n",
    "# 生成提交结果\n",
    "submit = submit.sort_values(by='name')\n",
    "submit.to_csv('submit5.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = validate(val_loader, model)\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=XunFeiDataset(train_path[:-1000], train_label[:-1000],\n",
    "            A.Compose([\n",
    "            # A.RandomRotate90(),\n",
    "            A.Resize(256, 256),\n",
    "            A.RandomCrop(224, 224),\n",
    "            # A.HorizontalFlip(p=0.5),\n",
    "            # A.RandomBrightnessContrast(p=0.5),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        )\n",
    "train_dataset, test_dataset=torch.utils.data.random_split(dataset=dataset,lengths=[0.9,0.1],generator=torch.Generator().manual_seed(42))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./model/baseline_test.pth\"))\n",
    "val_acc,val_loss = validate(val_loader, model, criterion)\n",
    "print(val_loss)\n",
    "len(val_loader.dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
